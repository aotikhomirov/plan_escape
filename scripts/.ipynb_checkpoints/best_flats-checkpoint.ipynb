{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import FancyURLopener, quote_plus\n",
    "from lxml.html import parse, document_fromstring\n",
    "from lxml.cssselect import CSSSelector\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#link = 'http://www.cian.ru/cat.php?deal_type=sale&engine_version=2&foot_min=25&metro%5B0%5D=245&minfloor=2&offer_type=flat&only_foot=2&room2=1'\n",
    "link = 'http://www.cian.ru/kupit-kvartiru-moskva-brateevo-0486/'\n",
    "urlOpener = FancyURLopener({})\n",
    "html = urlOpener.open(link).read()\n",
    "document = document_fromstring(html)\n",
    "pages = ['http://www.cian.ru'+ x.attrib['href'] for x in document.cssselect('.pager_pages a')]\n",
    "i = 1\n",
    "cnt_change = 1\n",
    "while cnt_change !=0 or i == 1000:\n",
    "    len_old = len(pages)\n",
    "    link_tmp = pages[-1]\n",
    "    html_tmp = urlOpener.open(link_tmp).read()\n",
    "    document_tmp = document_fromstring(html_tmp)\n",
    "    pages_tmp = ['http://www.cian.ru'+ x.attrib['href'] for x in document_tmp.cssselect('.pager_pages a') if x.attrib['href']!=link]\n",
    "    pages = set(pages)\n",
    "    for x in pages_tmp:\n",
    "        pages.add(x)\n",
    "    pages = list(pages)\n",
    "    len_new = len(pages)\n",
    "    cnt_change = len_new - len_old\n",
    "    i=i+1\n",
    "pages.append(link)\n",
    "\n",
    "urls = []\n",
    "#ids = []\n",
    "for link_tmp in pages:\n",
    "    html_tmp = urlOpener.open(link_tmp).read()\n",
    "    document_tmp = document_fromstring(html_tmp)\n",
    "    flats_info = document_tmp.cssselect('#content')\n",
    "    flat = flats_info[0].cssselect('.serp-list .serp-item')\n",
    "    for i in range(len(flat)):\n",
    "        #ids.append(flat[i].attrib['oid'])\n",
    "        urls.append(flat[i].attrib['href'])\n",
    "urls = set(urls)\n",
    "df = pd.DataFrame(columns=('url','cnt_rooms', 'price_all', 'total_area','address','metro','dt_metro', 'popularity','time_of_posting',\n",
    "                           'floor', 'living_area','kitchen_area','elevator','toilet','message','year_of_construction', 'house_type',\n",
    "                           'cnt_floors','cnt_entrance', 'cnt_flats','avg_price_m2_in_house','avg_rental_rate','name_of_district',\n",
    "                           'district_population','avg_age','avg_price_m2_in_district'))\n",
    "for i,u in enumerate(urls):   \n",
    "    #dict_tmp = {'url':None,'price_all':None,'square_all':None,'address':None}\n",
    "    res = []\n",
    "    flat_tmp = document_fromstring(urlOpener.open(u).read())\n",
    "    price_all = flat_tmp.cssselect('#price_rur')\n",
    "    square_all = flat_tmp.cssselect('.object_descr_props tr:nth-child(5) td')\n",
    "    address = flat_tmp.cssselect('.object_descr_addr a')\n",
    "    #dict_tmp['url'] = urls[1]\n",
    "    res.append(u)\n",
    "    res.append(flat_tmp.cssselect('.object_descr_title')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "    #dict_tmp['price_all'] = float(price_all[0].text_content().replace(',','.'))\n",
    "    res.append(float(price_all[0].text_content().replace(',','.')))\n",
    "    s = square_all[0]\n",
    "    s = s.text_content()\n",
    "    #dict_tmp['square_all'] = int(''.join(x for x in s.strip() if x.isdigit())[0:2])\n",
    "    res.append(int(''.join(x for x in s.strip() if x.isdigit())[0:2]))\n",
    "    adrr = [f.text_content() for f in address]\n",
    "    #dict_tmp['address'] = ' '.join(x for x in adrr)\n",
    "    res.append(' '.join(x for x in adrr))\n",
    "    res.append(flat_tmp.cssselect('.object_descr_metro a')[0].text_content())\n",
    "    if len(flat_tmp.cssselect('.object_item_metro_comment')) != 0:\n",
    "           res.append(re.sub(' +',' ',flat_tmp.cssselect('.object_item_metro_comment')[0].text_content().replace('\\n','')))\n",
    "    else:\n",
    "        res.append('')\n",
    "    res.append(flat_tmp.cssselect('.object_descr_dt_added a')[0].text_content())\n",
    "    res.append(flat_tmp.cssselect('.object_descr_dt_added')[1].text_content())\n",
    "    res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(2) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "    res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(7) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "    res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(8) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "    res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(11) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "    res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(9) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "    s = re.sub(' +',' ',flat_tmp.cssselect('.object_descr_text')[0].text_content().replace('\\n',''))\n",
    "    res.append(s[0:(s.find('/*')-1)])\n",
    "    if len(flat_tmp.cssselect('.bti__data tbody')) != 0:        \n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(1) td')[0].text_content())\n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(2) td')[0].text_content())\n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(3) td')[0].text_content())\n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(4) td')[0].text_content())\n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(5) td')[0].text_content())\n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(6) td')[0].text_content())\n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(8) td')[0].text_content())\n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[1].cssselect('tr:nth-child(1) td')[0].text_content())\n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[1].cssselect('tr:nth-child(3) td')[0].text_content())\n",
    "        res.append(flat_tmp.cssselect('.bti__data tbody')[1].cssselect('tr:nth-child(4) td')[0].text_content())\n",
    "        res.append(re.sub(' +',' ',flat_tmp.cssselect('.bti__data tbody')[1].cssselect('tr:nth-child(5) td')[0].text_content().replace('\\n','')))\n",
    "    else:\n",
    "        for j in range(11):\n",
    "            res.append('')            \n",
    "    df.loc[i] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#импорт необходимых библиотек \n",
    "from urllib import FancyURLopener, quote_plus\n",
    "from lxml.html import parse, document_fromstring\n",
    "from lxml.cssselect import CSSSelector\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def best_flats(link):\n",
    "    urlOpener = FancyURLopener({})\n",
    "    main_page_doc = document_fromstring(urlOpener.open(link).read())\n",
    "    pages = ['http://www.cian.ru'+ x.attrib['href'] for x in main_page_doc.cssselect('.pager_pages a')]\n",
    "\n",
    "    cnt_change = 1\n",
    "    while cnt_change !=0:\n",
    "        len_old = len(pages)\n",
    "        page_last = pages[-1]\n",
    "        page_last_doc = document_fromstring(urlOpener.open(page_last).read())\n",
    "        pages_delta = ['http://www.cian.ru'+ x.attrib['href'] \n",
    "                       for x in page_last_doc.cssselect('.pager_pages a')\n",
    "                       if x.attrib['href']!=link]\n",
    "        pages = set(pages)\n",
    "        for x in pages_delta:\n",
    "            pages.add(x)\n",
    "        pages = list(pages)\n",
    "        len_new = len(pages)\n",
    "        cnt_change = len_new - len_old\n",
    "    pages.append(link)\n",
    "    \n",
    "    urls = []\n",
    "    for p in pages:\n",
    "        flat_doc = document_fromstring(urlOpener.open(p).read())\n",
    "        flats_info = flat_doc.cssselect('#content')\n",
    "        flat = flats_info[0].cssselect('.serp-list .serp-item')\n",
    "        for i in range(len(flat)):\n",
    "            urls.append(flat[i].attrib['href'])\n",
    "    urls = set(urls)\n",
    "    df = pd.DataFrame(columns=('url','cnt_rooms', 'price_all', 'total_area','address','metro','dt_metro',\n",
    "                               'popularity','time_of_posting', 'floor', 'living_area','kitchen_area',\n",
    "                               'elevator','toilet','message','year_of_construction', 'house_type',\n",
    "                               'cnt_floors','cnt_entrance', 'cnt_flats','avg_price_m2_in_house','avg_rental_rate',\n",
    "                               'name_of_district','district_population','avg_age','avg_price_m2_in_district'))\n",
    "    for i,u in enumerate(urls):   \n",
    "        res = []\n",
    "        flat_tmp = document_fromstring(urlOpener.open(u).read())\n",
    "        price_all = flat_tmp.cssselect('#price_rur')\n",
    "        square_all = flat_tmp.cssselect('.object_descr_props tr:nth-child(5) td')\n",
    "        address = flat_tmp.cssselect('.object_descr_addr a')\n",
    "        res.append(u)\n",
    "        if len(flat_tmp.cssselect('.object_descr_title')) != 0:\n",
    "            res.append(flat_tmp.cssselect('.object_descr_title')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "        else:\n",
    "            res.append('')\n",
    "        if len(price_all) != 0:\n",
    "            res.append(float(price_all[0].text_content().replace(',','.')))\n",
    "        else:\n",
    "            res.append('')\n",
    "        if len(square_all) != 0:\n",
    "            s = square_all[0]\n",
    "            s = s.text_content()\n",
    "            res.append(''.join(x for x in s.strip() if x.isdigit())[0:2])\n",
    "        else:\n",
    "            res.append('')\n",
    "        if len(address) != 0:\n",
    "            adrr = [f.text_content() for f in address]\n",
    "            res.append(' '.join(x for x in adrr))\n",
    "        else:\n",
    "            res.append('')\n",
    "        if len(flat_tmp.cssselect('.object_descr_metro a')) != 0:\n",
    "            res.append(flat_tmp.cssselect('.object_descr_metro a')[0].text_content())\n",
    "        else:\n",
    "            res.append('')\n",
    "        if len(flat_tmp.cssselect('.object_item_metro_comment')) != 0:\n",
    "               res.append(re.sub(' +',' ',flat_tmp.cssselect('.object_item_metro_comment')[0].text_content().replace('\\n','')))\n",
    "        else:\n",
    "            res.append('')\n",
    "        if len(flat_tmp.cssselect('.object_descr_dt_added a')) != 0:\n",
    "            res.append(flat_tmp.cssselect('.object_descr_dt_added a')[0].text_content())\n",
    "        else:\n",
    "            res.append('')\n",
    "        if len(flat_tmp.cssselect('.object_descr_dt_added')) > 1:\n",
    "            res.append(flat_tmp.cssselect('.object_descr_dt_added')[1].text_content())\n",
    "        else:\n",
    "            res.append('')        \n",
    "        res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(2) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "        res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(7) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "        res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(8) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "        res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(11) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "        res.append(flat_tmp.cssselect('.object_descr_props tr:nth-child(9) td')[0].text_content().replace(' ','').replace('\\n',''))\n",
    "        s = re.sub(' +',' ',flat_tmp.cssselect('.object_descr_text')[0].text_content().replace('\\n',''))\n",
    "        res.append(s[0:(s.find('/*')-1)])\n",
    "        if len(flat_tmp.cssselect('.bti__data tbody')) != 0:        \n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(1) td')[0].text_content())\n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(2) td')[0].text_content())\n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(3) td')[0].text_content())\n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(4) td')[0].text_content())\n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(5) td')[0].text_content())\n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(6) td')[0].text_content())\n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[0].cssselect('tr:nth-child(8) td')[0].text_content())\n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[1].cssselect('tr:nth-child(1) td')[0].text_content())\n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[1].cssselect('tr:nth-child(3) td')[0].text_content())\n",
    "            res.append(flat_tmp.cssselect('.bti__data tbody')[1].cssselect('tr:nth-child(4) td')[0].text_content())\n",
    "            res.append(re.sub(' +',' ',flat_tmp.cssselect('.bti__data tbody')[1].cssselect('tr:nth-child(5) td')[0].text_content().replace('\\n','')))\n",
    "        else:\n",
    "            for j in range(11):\n",
    "                res.append('')            \n",
    "        df.loc[i] = res\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brateevo = best_flats('http://www.cian.ru/kupit-kvartiru-moskva-brateevo-0486/')\n",
    "print 'brateevo'\n",
    "zyablikovo = best_flats('http://www.cian.ru/kupit-kvartiru-moskva-zyablikovo-0489/')\n",
    "print 'zyablikovo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orehovo_borisovo_yuzhnoe = best_flats('http://www.cian.ru/kupit-kvartiru-moskva-orehovo-borisovo-yuzhnoe-0495/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brateevo.to_excel(u'C:\\\\Users\\\\Valery\\\\Desktop\\\\cian\\\\brateevo_110916.xlsx')\n",
    "zyablikovo.to_excel(u'C:\\\\Users\\\\Valery\\\\Desktop\\\\cian\\\\zyablikovo_110916.xlsx')\n",
    "orehovo_borisovo_yuzhnoe.to_excel(u'C:\\\\Users\\\\Valery\\\\Desktop\\\\cian\\\\orehovo_borisovo_yuzhnoe_110916.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del brateevo, zyablikovo, orehovo_borisovo_yuzhnoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orehovo_borisovo_severnoe = best_flats('http://www.cian.ru/kupit-kvartiru-vtorichka-moskva-orehovo-borisovo-severnoe-0494/')\n",
    "orehovo_borisovo_severnoe.to_excel(u'C:\\\\Users\\\\Valery\\\\Desktop\\\\cian\\\\orehovo_borisovo_severnoe_110916.xlsx')\n",
    "del orehovo_borisovo_severnoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moskvoreche_saburovo = best_flats('http://www.cian.ru/kupit-kvartiru-moskva-moskvoreche-saburovo-0490/')\n",
    "moskvoreche_saburovo.to_excel(u'C:\\\\Users\\\\Valery\\\\Desktop\\\\cian\\\\moskvoreche_saburovo_060916.xlsx')\n",
    "del moskvoreche_saburovo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caricyno = best_flats('http://www.cian.ru/kupit-kvartiru-moskva-caricyno-0496/')\n",
    "caricyno.to_excel(u'C:\\\\Users\\\\Valery\\\\Desktop\\\\cian\\\\caricyno_110916.xlsx')\n",
    "del caricyno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nagatino_sadovniki = best_flats('http://www.cian.ru/kupit-kvartiru-moskva-nagatino-sadovniki-0491/')\n",
    "nagatino_sadovniki.to_excel(u'C:\\\\Users\\\\Valery\\\\Desktop\\\\cian\\\\nagatino_sadovniki_110916.xlsx')\n",
    "del nagatino_sadovniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link_search = 'http://www.cian.ru/cat.php?acontext=%D0%B0%D0%BF%D0%B0%D1%80%D1%82%D0%B0%D0%BC%D0%B5%D0%BD%D1%82%D1%8B&currency=2&deal_type=sale&engine_version=2&foot_min=20&maxprice=8000000&metro%5B0%5D=1&metro%5B10%5D=20&metro%5B11%5D=21&metro%5B12%5D=22&metro%5B13%5D=27&metro%5B14%5D=32&metro%5B15%5D=38&metro%5B16%5D=39&metro%5B17%5D=40&metro%5B18%5D=41&metro%5B19%5D=43&metro%5B1%5D=2&metro%5B20%5D=45&metro%5B21%5D=46&metro%5B22%5D=47&metro%5B23%5D=48&metro%5B24%5D=49&metro%5B25%5D=50&metro%5B26%5D=52&metro%5B27%5D=53&metro%5B28%5D=54&metro%5B29%5D=55&metro%5B2%5D=4&metro%5B30%5D=56&metro%5B31%5D=58&metro%5B32%5D=61&metro%5B33%5D=64&metro%5B34%5D=65&metro%5B35%5D=66&metro%5B36%5D=67&metro%5B37%5D=68&metro%5B38%5D=71&metro%5B39%5D=76&metro%5B3%5D=5&metro%5B40%5D=77&metro%5B41%5D=78&metro%5B42%5D=80&metro%5B43%5D=82&metro%5B44%5D=84&metro%5B45%5D=85&metro%5B46%5D=86&metro%5B47%5D=88&metro%5B48%5D=89&metro%5B49%5D=90&metro%5B4%5D=8&metro%5B50%5D=92&metro%5B51%5D=95&metro%5B52%5D=96&metro%5B53%5D=98&metro%5B54%5D=100&metro%5B55%5D=101&metro%5B56%5D=103&metro%5B57%5D=105&metro%5B58%5D=107&metro%5B59%5D=111&metro%5B5%5D=8&metro%5B60%5D=113&metro%5B61%5D=114&metro%5B62%5D=115&metro%5B63%5D=115&metro%5B64%5D=117&metro%5B65%5D=119&metro%5B66%5D=121&metro%5B67%5D=123&metro%5B68%5D=124&metro%5B69%5D=125&metro%5B6%5D=12&metro%5B70%5D=129&metro%5B71%5D=130&metro%5B72%5D=132&metro%5B73%5D=137&metro%5B74%5D=144&metro%5B75%5D=145&metro%5B76%5D=146&metro%5B77%5D=148&metro%5B78%5D=149&metro%5B79%5D=150&metro%5B7%5D=13&metro%5B80%5D=152&metro%5B81%5D=155&metro%5B82%5D=159&metro%5B83%5D=238&metro%5B84%5D=239&metro%5B85%5D=240&metro%5B86%5D=245&metro%5B87%5D=283&metro%5B8%5D=15&metro%5B9%5D=18&offer_type=flat&only_foot=2'\n",
    "\n",
    "search = best_flats(link_search)\n",
    "search.to_excel(u'C:\\\\Users\\\\Valery\\\\Desktop\\\\cian\\\\search_060916.xlsx')\n",
    "del search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(u'C:\\\\Users\\\\Valery\\\\Desktop\\\\cian\\\\caricyno_060916.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.cnt_rooms.apply(lambda x: int(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-86d2752b2ce1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mflat_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocument_fromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlOpener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mflats_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflat_doc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcssselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#content'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mflat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflats_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcssselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.serp-list .serp-item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0murls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from urllib import FancyURLopener\n",
    "from lxml.html import document_fromstring\n",
    "from lxml.cssselect import CSSSelector\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "link = 'http://www.cian.ru/kupit-kvartiru-moskva-nagatino-sadovniki-0491/'\n",
    "urlOpener = FancyURLopener({})\n",
    "main_page_doc = document_fromstring(urlOpener.open(link).read())\n",
    "pages = ['http://www.cian.ru'+ x.attrib['href'] for x in main_page_doc.cssselect('.pager_pages a')]\n",
    "cnt_change = 1\n",
    "while cnt_change !=0:\n",
    "    len_old = len(pages)\n",
    "    page_last = pages[-1]\n",
    "    page_last_doc = document_fromstring(urlOpener.open(page_last).read())\n",
    "    pages_delta = ['http://www.cian.ru'+ x.attrib['href'] \n",
    "                   for x in page_last_doc.cssselect('.pager_pages a')\n",
    "                   if x.attrib['href']!=link]\n",
    "    pages = set(pages)\n",
    "    for x in pages_delta:\n",
    "        pages.add(x)\n",
    "    pages = list(pages)\n",
    "    numbers_of_pages = [int(re.findall(\"p=(\\d+)\",x)[0]) for x in pages]\n",
    "    index_sort = sorted(range(len(numbers_of_pages)), key=lambda k: numbers_of_pages[k])\n",
    "    pages = [pages[i] for i in index_sort]\n",
    "    len_new = len(pages)\n",
    "    cnt_change = len_new - len_old\n",
    "pages.append(link)\n",
    "\n",
    "urls = []\n",
    "for p in pages:\n",
    "    flat_doc = document_fromstring(urlOpener.open(p).read())\n",
    "    flats_info = flat_doc.cssselect('#content')\n",
    "    flat = flats_info[0].cssselect('.serp-list .serp-item')\n",
    "    for i in range(len(flat)):\n",
    "        urls.append(flat[i].attrib['href'])\n",
    "urls = set(urls)\n",
    "urls = list(urls)\n",
    "os.makedirs(\"C:\\Users\\Valery\\Desktop\\plan_escape\\data\\\\\"+ re.sub(\"-\",\"\",str(datetime.date.today())))\n",
    "os.chdir(\"C:\\Users\\Valery\\Desktop\\plan_escape\\data\\\\\"+ re.sub(\"-\",\"\",str(datetime.date.today())))\n",
    "for u in urls[0:5]:\n",
    "    file_name = re.findall(\"/(\\d+)/\",u)[0]+\"_\"+re.sub(\"-\",\"\",str(datetime.date.today()))+\".txt\"\n",
    "    flat = urlOpener.open(u).read()\n",
    "    text_file = open(file_name, \"w\")\n",
    "    text_file.write(flat)\n",
    "    text_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://www.cian.ru/cat.php?deal_type=sale&district%5B0%5D=91&engine_version=2&offer_type=flat&p=16'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print flat_doc.cssselect('#content')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_doc = document_fromstring(urlOpener.open(p).read())\n",
    "flats_info = flat_doc.cssselect('#content')\n",
    "flat = flats_info[0].cssselect('.serp-list .serp-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = re.findall(\"/(\\d+)/\",urls[0])[0]+\"_\"+re.sub(\"-\",\"\",str(datetime.date.today()))+\".txt\"\n",
    "flat = urlOpener.open(urls[0]).read()\n",
    "text_file = open(file_name, \"w\")\n",
    "text_file.write(flat)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.findall(\"/(\\d+)/\",urls[0])[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def raw_data(link, path_data):\n",
    "    #импорт библиотек\n",
    "    from urllib import FancyURLopener\n",
    "    from lxml.html import document_fromstring\n",
    "    from lxml.cssselect import CSSSelector\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    import time\n",
    "    import random\n",
    "    import os\n",
    "\n",
    "    urlOpener = FancyURLopener({})\n",
    "    main_page_doc = document_fromstring(urlOpener.open(link).read())\n",
    "    pages = ['http://www.cian.ru'+ x.attrib['href'] for x in main_page_doc.cssselect('.pager_pages a')]\n",
    "    cnt_change = 1\n",
    "    while cnt_change !=0:\n",
    "        len_old = len(pages)\n",
    "        page_last = pages[-1]\n",
    "        page_last_doc = document_fromstring(urlOpener.open(page_last).read())\n",
    "        pages_delta = ['http://www.cian.ru'+ x.attrib['href'] \n",
    "                       for x in page_last_doc.cssselect('.pager_pages a')\n",
    "                       if x.attrib['href']!=link]\n",
    "        pages = set(pages)\n",
    "        for x in pages_delta:\n",
    "            pages.add(x)\n",
    "        pages = list(pages)\n",
    "        numbers_of_pages = [int(re.findall(\"p=(\\d+)\",x)[0]) for x in pages]\n",
    "        index_sort = sorted(range(len(numbers_of_pages)), key=lambda k: numbers_of_pages[k])\n",
    "        pages = [pages[i] for i in index_sort]\n",
    "        len_new = len(pages)\n",
    "        cnt_change = len_new - len_old\n",
    "    pages.append(link)\n",
    "\n",
    "    urls = []\n",
    "    for p in pages:\n",
    "        flat_doc = document_fromstring(urlOpener.open(p).read())\n",
    "        time.sleep(random.uniform(0,1.5))\n",
    "        flats_info = flat_doc.cssselect('#content')\n",
    "        flats = flats_info[0].cssselect('.serp-list .serp-item')\n",
    "        for i in range(len(flats)):\n",
    "            urls.append(flats[i].attrib['href'])\n",
    "    urls = set(urls)\n",
    "    urls = list(urls)\n",
    "    str_today = re.sub(\"-\",\"\",str(datetime.date.today()))\n",
    "    os.makedirs(path_data + str_today)\n",
    "    os.chdir(path_data + str_today)\n",
    "    for u in urls:\n",
    "        file_name = re.findall(\"/(\\d+)/\",u)[0]+\"_\"+str_today+\".txt\"\n",
    "        flat = urlOpener.open(u).read()\n",
    "        \n",
    "        time.sleep(random.uniform(0,1.5))\n",
    "        \n",
    "        text_file = open(file_name, \"w\")\n",
    "        text_file.write(flat)\n",
    "        text_file.close()\n",
    "    return \"raw data downloaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raw data downloaded'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data('http://www.cian.ru/kupit-kvartiru-moskva-nagatino-sadovniki-0491/',\"C:\\Users\\Valery\\Desktop\\plan_escape\\data\\\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
